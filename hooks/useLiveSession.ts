// ... (d√©but de la fonction connect inchang√©)

      // 1. On √©tablit la connexion
      const session = await aiClientRef.current.live.connect({
        model: 'gemini-2.0-flash-exp',
        config: {
          responseModalities: "AUDIO" as any,
          speechConfig: {
            voiceConfig: { prebuiltVoiceConfig: { voiceName: 'Kore' } },
          },
          systemInstruction: { parts: [{ text: systemInstruction }] },
        },
        callbacks: {
            onopen: () => {
                console.log("‚úÖ [CONNEXION] Session ouverte.");
                setStatus('connected');
            },
            onclose: () => {
                console.log("‚ùå [CONNEXION] Session ferm√©e.");
                setStatus('disconnected');
            },
            onmessage: (msg: LiveServerMessage) => {
                processServerMessage(msg);
            },
            onerror: (e) => {
                console.error("‚ö†Ô∏è [ERREUR] Session error", e);
                setStatus('error');
            }
        }
      });

      // 2. ON SAUVEGARDE LA SESSION (C'est l√† que √ßa plantait avant)
      currentSessionRef.current = session;
      
      // 3. LE PING DE R√âVEIL (Maintenant c'est s√ªr, la session existe !)
      console.log("üì® [TEST] Envoi du message texte 'Bonjour' pour forcer l'audio...");
      await session.send({
          parts: [{ text: "Bonjour ! Confirme-moi que tu m'entends." }],
          endOfTurn: true
      });

      // 4. On active le micro
      await startAudioInput();

    } catch (error) {
      console.error('Connection failed:', error);
      setStatus('error');
      disconnect();
    }
  };
